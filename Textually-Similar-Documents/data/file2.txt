Data-intensive applications work with large datasets (petabytes and beyond). These datasets are usually stored across multiple different machines/servers in different locations around the world in a distributed system manner which makes the processing of this data a multistep analysis pipeline where different transformations are applied to these datasets in each step. This processing mechanism needs to scale as the dataset size increases over time. Data-intensive applications face the challenges of efficient data storage management, partitioning, replication, computing models and algorithms that can be scaled to improve the performance of these applications working with data ranging in petabytes and beyond. The open challenges in data-intensive computing are many but the fundamental challenges in data-intensive computing are to managing the huge volumes of incoming data, reducing the data through transformations for better analysis and designing new algorithms for supporting scaling and searching through these massive datasets.